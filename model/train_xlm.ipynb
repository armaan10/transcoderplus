{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_xlm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOgO7FEAemM9a1eDT07aPrd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/armaan10/transcoderplus/blob/v1/model/train_xlm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yWMuQXmezmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "beb7040e-d1de-44ae-dcef-56008a415df5"
      },
      "source": [
        "!unzip utils.zip\n",
        "!unzip bpe_files.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  utils.zip\n",
            "   creating: utils/\n",
            " extracting: utils/__init__.py       \n",
            "  inflating: utils/stat_collector.py  \n",
            "  inflating: utils/parser.py         \n",
            "  inflating: utils/link.py           \n",
            "   creating: utils/__pycache__/\n",
            "  inflating: utils/__pycache__/link.cpython-38.pyc  \n",
            "  inflating: utils/__pycache__/parser.cpython-38.pyc  \n",
            "  inflating: utils/code_tokenizer.py  \n",
            "Archive:  bpe_files.zip\n",
            "   creating: bpe_files/\n",
            "  inflating: bpe_files/tokeinzed_cpp.txt  \n",
            "  inflating: bpe_files/py_train      \n",
            "  inflating: bpe_files/cpp_train_vocab  \n",
            "  inflating: bpe_files/codes         \n",
            "  inflating: bpe_files/py_train_bpe  \n",
            "  inflating: bpe_files/py_cpp_concat.txt  \n",
            "  inflating: bpe_files/cpp_train_bpe  \n",
            "  inflating: bpe_files/tokeinzed_py.txt  \n",
            "  inflating: bpe_files/fn_cpp_tokens.txt  \n",
            "  inflating: bpe_files/cpp_train     \n",
            "  inflating: bpe_files/py_train_vocab  \n",
            "  inflating: bpe_files/fn_cpp.txt    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0d3OIdQh4Gx"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(1, './utils')\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "import link\n",
        "import parser\n",
        "import random\n",
        "import time\n",
        "import math\n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu6u61lMiz_I"
      },
      "source": [
        "class EncoderNet(nn.Module):\n",
        "    def __init__ (self,vocab_size,model_dim,att_h,output_dim,num_layers,pad_idx):\n",
        "        super(EncoderNet,self).__init__()\n",
        "        self.encoder_layer=nn.TransformerEncoderLayer(model_dim,att_h,output_dim)   \n",
        "        self.encoder=nn.TransformerEncoder(self.encoder_layer,num_layers)\n",
        "        self.pos_enc=PositionalEncoding(model_dim)\n",
        "        self.emd_py=nn.Embedding(vocab_size[0],model_dim,padding_idx=pad_idx[0])\n",
        "        self.emd_cpp=nn.Embedding(vocab_size[1],model_dim,padding_idx=pad_idx[1])\n",
        "        self.linear_py=nn.Linear(output_dim,vocab_size[0])\n",
        "        self.linear_cpp=nn.Linear(output_dim,vocab_size[1])\n",
        "    #pad_idx 1 -> pad it there mask_idx 1-> masked idx    \n",
        "    def forward(self,token_idx,mask_matrix,pad_idx,lang):\n",
        "        \n",
        "        if lang==\"py\":\n",
        "            inp_vec=self.emd_py(token_idx)\n",
        "        else :\n",
        "            inp_vec=self.emd_cpp(token_idx)\n",
        "        if self.training:\n",
        "          try:\n",
        "            assert inp_vec.size()==mask_matrix.size()\n",
        "          except AssertionError as error:\n",
        "            error.args+=(inp_vec.size(),mask_matrix.size())\n",
        "            raise\n",
        "          #create random vector for mask token\n",
        "        \n",
        "          inp_vec=(inp_vec*mask_matrix)\n",
        "        inp_vec=self.pos_enc(inp_vec)\n",
        "        output=self.encoder(inp_vec)\n",
        "        if not self.training:\n",
        "          return output \n",
        "        if lang==\"py\":\n",
        "            output=self.linear_py(output)\n",
        "        else:\n",
        "            output=self.linear_cpp(output)\n",
        "        #output=F.softmax(output)\n",
        "        return output\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:x.size(0), :]\n",
        "        return self.dropout(x)\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIejVQN4jGX8"
      },
      "source": [
        "\n",
        "def make_batches(tokens,no_seqs=32,inp_l=16,pad=True):\n",
        "    no_iters=int(len(tokens)/(no_seqs*inp_l))\n",
        "    batches=[]\n",
        "    total_batch_l=(no_seqs*inp_l)\n",
        "    \n",
        "    for i in range(no_iters):\n",
        "        batch=tokens[i*total_batch_l:(i+1)*(total_batch_l)]\n",
        "        seqs=[]\n",
        "        for j in range(no_seqs):\n",
        "            seqs.append(batch[j*inp_l:inp_l*(j+1)])\n",
        "\n",
        "        batches.append(seqs)\n",
        "    rem_batch=tokens[total_batch_l*no_iters:]\n",
        "    no_iters=int(len(rem_batch)/inp_l)\n",
        "    \n",
        "    seqs=[]\n",
        "    if len(rem_batch)>0:\n",
        "      for i in range(no_iters):\n",
        "          seqs.append(rem_batch[i*inp_l:(i+1)*inp_l])\n",
        "      #pad rem_batch\n",
        "      if pad:\n",
        "        padded_seq= rem_batch[no_iters*inp_l:]+[\"[PAD]\"]*abs(len(rem_batch[no_iters*inp_l:]) -inp_l)   \n",
        "        seqs.append(padded_seq)\n",
        "      else:\n",
        "        seqs.append(rem_batch[no_iters*inp_l:])\n",
        "      \n",
        "      batches.append(seqs)\n",
        "    return batches\n",
        "\n",
        "def mask_tokens(tokens,masking_per=15):\n",
        "    no_mask_tokens=int(len(tokens)*masking_per/100)\n",
        "    mask_idx=random.sample(range(0,len(tokens)),no_mask_tokens)\n",
        "    masked_token_l=[]\n",
        "    for i in mask_idx:\n",
        "        masked_token_l.append(tokens[i])\n",
        "        tokens[i]=\"[MASK]\"\n",
        "   \n",
        "    return tokens,masked_token_l    \n",
        "def make_targets(token_batch,dicto,vocab_vecs):\n",
        "    batch_v=[]\n",
        "    for batch in token_batch:\n",
        "        seq_v=[]\n",
        "        for seq in batch:\n",
        "            \n",
        "            \n",
        "            seq_v.append(link.lookup(seq,dicto,vocab_vecs))\n",
        "\n",
        "            #print(vecs.size())\n",
        "        #print(torch.stack(seq_v))\n",
        "        batch_v.append(torch.stack(seq_v))\n",
        "    return batch_v\n",
        "def get_tokens_idx(token_batch,dicto):\n",
        "    batch_v=[]\n",
        "    for batch in token_batch:\n",
        "        seq_v=[]\n",
        "        for seq in batch:\n",
        "            \n",
        "             l=torch.LongTensor([dicto[x] for x in seq ])\n",
        "             seq_v.append(l)\n",
        "        batch_v.append(torch.stack(seq_v))\n",
        "    return batch_v\n",
        "#in the form (batch,seqs,tokens)\n",
        "def get_mask_pad_matrix(embd_dim,token_batch,no_seqs,seq_l):\n",
        "    batch_mask=[]\n",
        "    batch_pad=[]\n",
        "    for batch in token_batch:\n",
        "        mask_seq=[]\n",
        "        zeros=torch.zeros(no_seqs,seq_l)\n",
        "        for seq in batch:\n",
        "            ones_matrix=torch.ones(len(seq),embd_dim)\n",
        "            if \"[MASK]\" in seq:\n",
        "                random_mask=torch.rand(1,embd_dim)\n",
        "                ones_matrix[seq.index(\"[MASK]\")]=random_mask\n",
        "            mask_seq.append(ones_matrix)\n",
        "        batch_mask.append(torch.stack(mask_seq))\n",
        "        batch_pad.append(zeros)\n",
        "    '''if \"[PAD]\" in token_batch[-1][-1]:\n",
        "        seq=token_batch[-1][-1]\n",
        "        pad_l=len(seq)-seq.index(\"[PAD]\")\n",
        "        pad_idx=torch.ones(1,pad_l)\n",
        "        batch_pad[-1][-1,seq.index(\"[PAD]\"):]=pad_idx'''\n",
        "    return batch_mask,batch_pad\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uplDqR9DjN4O"
      },
      "source": [
        "vocab_py=parser.read_file(\"./bpe_files/py_train_vocab\")\n",
        "tokens_py=parser.read_file(\"./bpe_files/py_train_bpe\")\n",
        "vocab_cpp=parser.read_file(\"./bpe_files/cpp_train_vocab\")\n",
        "tokens_cpp=parser.read_file(\"./bpe_files/cpp_train_bpe\")\n",
        "\n",
        "tokens_list_py=[]\n",
        "tokens_list_cpp=[]\n",
        "#imp part add later \n",
        "for i in tokens_py:\n",
        "        tokens_list_py+=i.split()\n",
        "for i in tokens_cpp:\n",
        "        tokens_list_cpp+=i.split()\n",
        "dict_py,size_py=link.create_dict(vocab_py)\n",
        "dict_cpp,size_cpp=link.create_dict(vocab_cpp)\n",
        "special_tks=[\"[MASK]\",\"[PAD]\"]\n",
        "dict_py[special_tks[0]]=size_py\n",
        "dict_py[special_tks[1]]=size_py+1\n",
        "size_py+=2\n",
        "dict_cpp[special_tks[0]]=size_cpp\n",
        "dict_cpp[special_tks[1]]=size_cpp+1\n",
        "size_cpp+=2\n",
        "pad_idx=[dict_py[special_tks[1]],dict_cpp[special_tks[1]]]\n",
        "#print(tokens_list_py)\n",
        "\n",
        "#reduce cpp for now\n",
        "tokens_list_cpp=tokens_list_cpp[:20000]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO4_BzgKjaxR"
      },
      "source": [
        "#encoder params def\n",
        "vocab_size=[size_py,size_cpp]\n",
        "model_dim=1024\n",
        "att_h=8\n",
        "output_dim=1024\n",
        "num_layers=6\n",
        "lr=0.001\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model=EncoderNet(vocab_size, model_dim, att_h, output_dim,num_layers,pad_idx).to(device)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=lr,betas=(0.9,0.98))\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEjGyTvejrFC"
      },
      "source": [
        "#training params\n",
        "no_seqs=32\n",
        "seq_l=16\n",
        "one_hot_vecs_py=torch.eye(size_py)\n",
        "one_hot_vecs_cpp=torch.eye(size_cpp)\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXgdyCo5jwpb",
        "outputId": "d5474265-73ac-4076-942d-415c9e1eafd0"
      },
      "source": [
        "\n",
        "def train(epochs=100):\n",
        "    model.train()\n",
        "    \n",
        "    #unmasked_train_set_py=make_batches(tokens_list_py)\n",
        "    #unmasked_train_set_cpp=make_batches(tokens_list_cpp)\n",
        "    #targets_py=make_targets(unmasked_train_set_py,dict_py,one_hot_vecs_py)\n",
        "    #print(len(token_list_cpp))\n",
        "    #targets_cpp=make_targets(unmasked_train_set_cpp,dict_cpp,one_hot_vecs_cpp)\n",
        "    epl=[]\n",
        "    l=[]\n",
        "    loss_total=0\n",
        "    #run funcs each batch at a time \n",
        "    start_time=time.time()\n",
        "    for ep in range(1,epochs+1):\n",
        "        no_batches_py=int(len(tokens_list_py)/(no_seqs*seq_l))\n",
        "        no_batches_cpp=int(len(tokens_list_cpp)/(no_seqs*seq_l))\n",
        "        \n",
        "        #mask tokens\n",
        "        masked_tokens_py,_=mask_tokens(tokens_list_py)\n",
        "        masked_tokens_cpp,_=mask_tokens(tokens_list_cpp)\n",
        "        iter_r=0\n",
        "        py_iter=0\n",
        "        cpp_iter=0\n",
        "        for batch_l in range(2*(max(no_batches_cpp,no_batches_py)+1)):\n",
        "          \n",
        "          if batch_l%2==0:\n",
        "            lang=\"py\"\n",
        "            if py_iter == no_batches_py:\n",
        "              mask_tokens_l = masked_tokens_py[py_iter*(no_seqs*seq_l):]        \n",
        "              tokens_list=tokens_list_py[py_iter*(no_seqs*seq_l):]\n",
        "            \n",
        "              \n",
        "            else:\n",
        "              mask_tokens_l = masked_tokens_py[py_iter*(no_seqs*seq_l):(py_iter+1)*no_seqs*seq_l]        \n",
        "              tokens_list=tokens_list_py[py_iter*(no_seqs*seq_l):(py_iter+1)*no_seqs*seq_l]\n",
        "            dicto=dict_py\n",
        "            one_hot_vecs=one_hot_vecs_py\n",
        "            py_iter=(py_iter+1)%(no_batches_py+1)\n",
        "          else :\n",
        "            lang=\"cpp\"\n",
        "            if cpp_iter== no_batches_cpp:\n",
        "              mask_tokens_l = masked_tokens_cpp[cpp_iter*(no_seqs*seq_l):]        \n",
        "              tokens_list=tokens_list_cpp[cpp_iter*(no_seqs*seq_l):]  \n",
        "            else:\n",
        "              mask_tokens_l = masked_tokens_cpp[cpp_iter*(no_seqs*seq_l):(cpp_iter+1)*no_seqs*seq_l]        \n",
        "              tokens_list=tokens_list_cpp[cpp_iter*(no_seqs*seq_l):(cpp_iter+1)*no_seqs*seq_l]\n",
        "\n",
        "            dicto=dict_cpp\n",
        "            one_hot_vecs=one_hot_vecs_cpp\n",
        "            cpp_iter=(cpp_iter+1)%(no_batches_cpp+1)\n",
        "          #make training stuff\n",
        "          masked_batch=make_batches(mask_tokens_l)\n",
        "          mask_mat,pad_mat=get_mask_pad_matrix(model_dim,masked_batch,no_seqs,seq_l)\n",
        "          \n",
        "         \n",
        "          masked_idx=get_tokens_idx(masked_batch,dicto)\n",
        "          \n",
        "          #make targets\n",
        "          targets=make_batches(tokens_list)\n",
        "          targets=make_targets(targets,dicto,one_hot_vecs)\n",
        "          optimizer.zero_grad()\n",
        "      \n",
        "          #lang.to(device)\n",
        "          #print(tokens_idx.size(),pad.size())\"\n",
        "          #print(\"LANGUAGE\",lang)\n",
        "          output = model(masked_idx[0].to(device),mask_mat[0].to(device),0,lang)\n",
        "          #print(output.view(no_seqs*seq_l,vocab_size[0]).size(),output.view(no_seqs*seq_l,vocab_size[0]).size())\n",
        "          output=output.view(-1,vocab_size[0 if lang==\"py\" else 1])\n",
        "          number_seqs=targets[0].size()[0]\n",
        "          targets=targets[0].view(number_seqs*seq_l,vocab_size[0 if lang==\"py\" else 1]).to(device).long()\n",
        "          targets=torch.argmax(targets,dim=1)\n",
        "          #output=torch.argmax(output,dim=1)\n",
        "          loss=criterion(output,targets)\n",
        "          #print(loss)\n",
        "          loss_total+=loss.item()\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          \n",
        "               \n",
        "\n",
        "        \"\"\" \n",
        "        #make into batches\n",
        "        masked_batch_py = make_batches(masked_tokens_py)\n",
        "        masked_batch_cpp=make_batches(masked_tokens_cpp)\n",
        "        #get padding and masking matrix\n",
        "        mask_py,pad_py=get_mask_pad_matrix(model_dim, masked_batch_py, no_seqs, seq_l)\n",
        "        mask_cpp,pad_cpp=get_mask_pad_matrix(model_dim, masked_batch_cpp, no_seqs, seq_l)\n",
        "        #get token indexes\n",
        "        masked_idx_py=get_tokens_idx(masked_batch_py, dict_py)\n",
        "        masked_idx_cpp=get_tokens_idx(masked_batch_cpp, dict_cpp)        \n",
        "        #alternate batches \n",
        "        loss_total=0    \n",
        "       \n",
        "        for iter_n in range (len(masked_batch_py)+len(masked_batch_cpp)):\n",
        "            py_iter=0\n",
        "            cpp_iter=0\n",
        "            if iter_n%2==0 or cpp_iter>=len(masked_batch_cpp) and py_iter<len(masked_batch):\n",
        "              tokens_idx=masked_idx_py[py_iter]\n",
        "              mask=mask_py[py_iter]\n",
        "              pad=pad_py[py_iter]\n",
        "              \n",
        "              targets=targets_py[py_iter]\n",
        "              py_iter+=1\n",
        "              lang=\"py\"\n",
        "         \n",
        "            else:\n",
        "                tokens_idx=masked_idx_cpp[cpp_iter]\n",
        "                mask=mask_cpp[cpp_iter]\n",
        "                pad=pad_cpp[cpp_iter]\n",
        "                targets=targets_cpp[cpp_iter]\n",
        "                cpp_iter+=1\n",
        "                \n",
        "                lang=\"cpp\"\n",
        "          \n",
        "            \"\"\"\n",
        "\n",
        "        log_int=10\n",
        "        if ep%log_int ==0:\n",
        "              end_time=time.time()\n",
        "              t=end_time-start_time\n",
        "              start_time=time.time()\n",
        "              print(\"time:\",t,\"epoch:\",ep,\"loss:\",loss_total/log_int)\n",
        "              epl.append(ep)\n",
        "              l.append(loss_total/log_int)\n",
        "              loss_total=0\n",
        "              \n",
        "    plt.plot(epl,l)\n",
        "train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 48.94403028488159 epoch: 10 loss: 224.11830483675004\n",
            "time: 48.540794134140015 epoch: 20 loss: 57.60091610699892\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXH20geSj4yh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "a31306a3-04d9-430a-989d-4938467624b7"
      },
      "source": [
        "model.eval()\n",
        "#index 0-py 1-cpp\n",
        "word_l=[['return','if','None'],['return','if','NULL']]\n",
        "def visualise_pretrain(word_list):\n",
        "\n",
        "  \n",
        "  color=['green','red']\n",
        "  langs=['py','cpp']\n",
        "  dict_l=[dict_py,dict_cpp]\n",
        "  fig,ax=plt.subplots()\n",
        "  for i,lang in enumerate(langs):\n",
        "    batches=make_batches(word_list[i],pad=False)\n",
        "    tokens_idx=get_tokens_idx(batches,dict_l[i])\n",
        "    \n",
        "    output=model(tokens_idx[0].to(device),0,0,lang)\n",
        "    print((output[0,1]==output[0,2]).sum())\n",
        "    \n",
        "    output=output.squeeze(0)\n",
        "   \n",
        "    output=output.cpu()\n",
        "    output=output.detach().numpy()\n",
        "    \n",
        "    points=TSNE(n_components=2).fit_transform(output)\n",
        "    ax.scatter(points[:,0],points[:,1],c=color[i])\n",
        "    for j,txt in enumerate(word_list[i]):\n",
        "      ax.annotate(txt,(points[j,0],points[j,1]))\n",
        "\n",
        "\n",
        "visualise_pretrain(word_l) \n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(310, device='cuda:0')\n",
            "tensor(310, device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j105pbaavoC9"
      },
      "source": [
        "X = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1]])\n",
        "X_embedded = TSNE(n_components=2).fit_transform(X) \n",
        "print(X_embedded,X_embedded[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6MX1dBL2EAe"
      },
      "source": [
        "l=[1,2,3]\n",
        "print(len(l[4:]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL3jJQTxG18R"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}